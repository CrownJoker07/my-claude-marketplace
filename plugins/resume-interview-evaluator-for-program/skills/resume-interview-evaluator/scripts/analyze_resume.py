#!/usr/bin/env python3
"""
ç®€å†è‡ªåŠ¨åˆ†æè„šæœ¬

åŠŸèƒ½ï¼š
    1. ä» PDF ç®€å†ä¸­æå–æ–‡æœ¬
    2. è§£æå…³é”®ä¿¡æ¯ï¼ˆå§“åã€å²—ä½ã€æŠ€èƒ½ã€é¡¹ç›®ç­‰ï¼‰
    3. ç”ŸæˆæŠ€èƒ½è¯„ä¼°æŠ¥å‘Š
    4. ç”Ÿæˆå®šåˆ¶åŒ–é¢è¯•é—®é¢˜æ¸…å•

ä½¿ç”¨æ–¹æ³•:
    # åŸºæœ¬ç”¨æ³•
    python3 analyze_resume.py /path/to/resume.pdf

    # æŒ‡å®šè¾“å‡ºç›®å½•
    python3 analyze_resume.py /path/to/resume.pdf -o ./output

    # æŒ‡å®šå€™é€‰äººå§“åï¼ˆå¦‚PDFä¸­æ— æ³•è¯†åˆ«ï¼‰
    python3 analyze_resume.py /path/to/resume.pdf --name "å¼ ä¸‰"

è¾“å‡º:
    - æŠ€èƒ½è¯„ä¼°æŠ¥å‘Š_{å§“å}_{æ—¥æœŸ}.md
    - é¢è¯•é—®é¢˜æ¸…å•_{å§“å}_{æ—¥æœŸ}.md
"""

import argparse
import os
import re
import sys
from datetime import datetime
from typing import Dict, List, Optional, Tuple


def extract_pdf_text(pdf_path: str) -> str:
    """
    ä» PDF æ–‡ä»¶ä¸­æå–æ–‡æœ¬

    ä¼˜å…ˆä½¿ç”¨ pdfplumberï¼ˆæ•ˆæœæ›´å¥½ï¼‰ï¼Œå¦‚æœªå®‰è£…åˆ™ä½¿ç”¨ PyPDF2
    """
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")

    # é¦–å…ˆå°è¯•ä½¿ç”¨ pdfplumber
    try:
        import pdfplumber
        with pdfplumber.open(pdf_path) as pdf:
            text = "\n".join(page.extract_text() or "" for page in pdf.pages)
            if text.strip():
                return text
    except ImportError:
        pass

    # å›é€€åˆ° PyPDF2
    try:
        from PyPDF2 import PdfReader
        reader = PdfReader(pdf_path)
        text = "\n".join(page.extract_text() or "" for page in reader.pages)
        return text
    except ImportError:
        raise ImportError(
            "è¯·å®‰è£… pdfplumber æˆ– PyPDF2:\n"
            "  pip install pdfplumber\n"
            "  æˆ–\n"
            "  pip install PyPDF2"
        )


def parse_resume(text: str) -> Dict:
    """
    è§£æç®€å†æ–‡æœ¬ï¼Œæå–å…³é”®ä¿¡æ¯

    è¿”å›ç»“æ„åŒ–æ•°æ®ï¼š
    {
        'name': str,
        'position': str,
        'experience_years': str,
        'education': str,
        'skills': {
            'languages': List[str],
            'engines': List[str],
            'professional': List[str],
            'tools': List[str]
        },
        'projects': List[Dict],
        'work_experience': List[str]
    }
    """
    lines = text.split('\n')

    result = {
        'name': '',
        'position': '',
        'experience_years': '',
        'education': '',
        'skills': {
            'languages': [],
            'engines': [],
            'professional': [],
            'tools': []
        },
        'projects': [],
        'work_experience': []
    }

    # æå–å§“åï¼ˆå¸¸è§æ ¼å¼ï¼šå§“åã€åå­—åœ¨å¼€å¤´ä½ç½®ï¼‰
    result['name'] = extract_name(text, lines)

    # æå–æœŸæœ›å²—ä½
    result['position'] = extract_position(text)

    # æå–å·¥ä½œå¹´é™
    result['experience_years'] = extract_experience_years(text)

    # æå–æ•™è‚²èƒŒæ™¯
    result['education'] = extract_education(text)

    # æå–æŠ€èƒ½ä¿¡æ¯
    result['skills'] = extract_skills(text)

    # æå–é¡¹ç›®ç»å†
    result['projects'] = extract_projects(text)

    # æå–å·¥ä½œç»å†
    result['work_experience'] = extract_work_experience(text)

    return result


def extract_name(text: str, lines: List[str]) -> str:
    """æå–å§“å"""
    # å°è¯•åŒ¹é…å¸¸è§çš„å§“åæ ‡è¯†
    patterns = [
        r'å§“\s*å[ï¼š:]\s*([^\n\s]+)',
        r'Name[ï¼š:]\s*([^\n\s]+)',
        r'^\s*([^\n\s]{2,4})\s*çš„?ç®€å†',
        r'([^\n\s]{2,4})\s*ä¸ªäººç®€å†',
    ]

    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            name = match.group(1).strip()
            # è¿‡æ»¤æ‰å¸¸è§çš„éå§“åè¯æ±‡
            if name and name not in ['ç®€å†', 'ä¸ªäºº', 'æˆ‘çš„']:
                return name

    # å°è¯•ä»ç¬¬ä¸€è¡Œæå–ï¼ˆé€šå¸¸æ˜¯å§“åï¼‰
    if lines:
        first_line = lines[0].strip()
        if first_line and len(first_line) <= 10:
            return first_line

    return 'æœªçŸ¥'


def extract_position(text: str) -> str:
    """æå–æœŸæœ›å²—ä½"""
    patterns = [
        r'æœŸæœ›èŒä½[ï¼š:]\s*([^\n]+)',
        r'åº”è˜èŒä½[ï¼š:]\s*([^\n]+)',
        r'ç›®æ ‡èŒä½[ï¼š:]\s*([^\n]+)',
        r'æ±‚èŒæ„å‘[ï¼š:]\s*([^\n]+)',
        r'æœŸæœ›å²—ä½[ï¼š:]\s*([^\n]+)',
    ]

    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return match.group(1).strip()

    # ä»æ–‡æœ¬ä¸­æ¨æ–­å²—ä½ç±»å‹
    if 'Unity' in text or 'unity' in text:
        return 'Unityæ¸¸æˆå¼€å‘å·¥ç¨‹å¸ˆ'
    elif 'Unreal' in text or 'UE' in text or 'è™šå¹»' in text:
        return 'UE4/UE5æ¸¸æˆå¼€å‘å·¥ç¨‹å¸ˆ'
    elif 'æ¸¸æˆ' in text and ('å¼€å‘' in text or 'ç¨‹åº' in text):
        return 'æ¸¸æˆå¼€å‘å·¥ç¨‹å¸ˆ'

    return 'æ¸¸æˆå¼€å‘å·¥ç¨‹å¸ˆ'


def extract_experience_years(text: str) -> str:
    """æå–å·¥ä½œå¹´é™"""
    patterns = [
        r'(\d+)\s*å¹´\s*(?:å·¥ä½œ|å¼€å‘)?ç»éªŒ',
        r'å·¥ä½œå¹´é™[ï¼š:]\s*(\d+)\s*å¹´',
        r'(\d+)\s*å¹´ä»¥ä¸Š?(?:ç›¸å…³)?ç»éªŒ',
        r'(åº”å±Š|æ ¡æ‹›|å®ä¹ ç”Ÿ?)',
    ]

    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            years = match.group(1)
            if years in ['åº”å±Š', 'æ ¡æ‹›', 'å®ä¹ ', 'å®ä¹ ç”Ÿ']:
                return 'åº”å±Šç”Ÿ/å®ä¹ '
            return f"{years}å¹´"

    return 'æœªçŸ¥'


def extract_education(text: str) -> str:
    """æå–æ•™è‚²èƒŒæ™¯"""
    # åŒ¹é…å­¦æ ¡åç§°
    school_patterns = [
        r'([^\n]+å¤§å­¦)',
        r'([^\n]+å­¦é™¢)',
        r'æ¯•ä¸šé™¢æ ¡[ï¼š:]\s*([^\n]+)',
        r'å­¦å†[ï¼š:]\s*([^\n]+)',
    ]

    for pattern in school_patterns:
        match = re.search(pattern, text)
        if match:
            school = match.group(1).strip()
            # æ£€æŸ¥æ˜¯å¦æœ‰å­¦å†ä¿¡æ¯
            degree_match = re.search(r'(æœ¬ç§‘|ç¡•å£«|åšå£«|ä¸“ç§‘|å¤§ä¸“|ç ”ç©¶ç”Ÿ)', text)
            if degree_match:
                return f"{school} {degree_match.group(1)}"
            return school

    return ''


def extract_skills(text: str) -> Dict[str, List[str]]:
    """æå–æŠ€èƒ½ä¿¡æ¯"""
    skills = {
        'languages': [],
        'engines': [],
        'professional': [],
        'tools': []
    }

    # ç¼–ç¨‹è¯­è¨€
    lang_keywords = {
        'C#': ['C#', 'CSharp', 'csharp'],
        'C++': ['C++', 'CPP', 'cpp'],
        'Python': ['Python', 'python'],
        'Lua': ['Lua', 'lua'],
        'JavaScript': ['JavaScript', 'JS', 'js'],
        'TypeScript': ['TypeScript', 'TS', 'ts'],
        'Java': ['Java', 'java'],
        'Go': ['Go', 'Golang', 'golang'],
    }

    for lang, keywords in lang_keywords.items():
        for kw in keywords:
            if kw in text:
                if lang not in skills['languages']:
                    skills['languages'].append(lang)
                break

    # æ¸¸æˆå¼•æ“
    engine_keywords = {
        'Unity': ['Unity', 'unity', 'Unity3D', 'U3D'],
        'Unreal Engine': ['Unreal', 'UE4', 'UE5', 'è™šå¹»å¼•æ“', 'è™šå¹»'],
        'Godot': ['Godot', 'godot'],
        'Cocos': ['Cocos', 'cocos', 'Cocos2d', 'Cocos Creator'],
    }

    for engine, keywords in engine_keywords.items():
        for kw in keywords:
            if kw in text:
                if engine not in skills['engines']:
                    skills['engines'].append(engine)
                break

    # ä¸“ä¸šæŠ€èƒ½
    prof_keywords = [
        'ECS', 'DOTS', 'Job System',
        'Shader', 'HLSL', 'GLSL', 'ShaderLab',
        'AI', 'è¡Œä¸ºæ ‘', 'çŠ¶æ€æœº', 'FSM',
        'å¯»è·¯', 'Navigation', 'NavMesh', 'A*',
        'ç½‘ç»œ', 'ç½‘ç»œåŒæ­¥', 'å¸§åŒæ­¥', 'çŠ¶æ€åŒæ­¥',
        'çƒ­æ›´æ–°', 'AssetBundle', 'Addressable',
        'UI', 'UGUI', 'FairyGUI',
        'ç‰©ç†', 'Physics', 'ç¢°æ’æ£€æµ‹',
        'æ€§èƒ½ä¼˜åŒ–', 'å†…å­˜ä¼˜åŒ–', 'Draw Call',
        'Lua', 'XLua', 'ToLua', 'SLua',
        'è®¾è®¡æ¨¡å¼', 'æ¶æ„è®¾è®¡', 'MVC', 'MVP', 'MVVM',
        'å¤šçº¿ç¨‹', 'å¼‚æ­¥ç¼–ç¨‹', 'UniTask', 'async/await',
        'ç‰ˆæœ¬æ§åˆ¶', 'Git', 'SVN'
    ]

    for kw in prof_keywords:
        if kw in text and kw not in skills['professional']:
            skills['professional'].append(kw)

    # å·¥å…·
    tool_keywords = [
        'Visual Studio', 'VS Code', 'Rider',
        'Git', 'SVN', 'Perforce',
        'Jenkins', 'CI/CD',
        'Jira', 'Confluence', 'Trello',
        'Profiler', 'Frame Debugger',
        'Blender', 'Maya', '3ds Max',
        'Photoshop', 'PS',
        'Wwise', 'FMOD', 'Audio',
        'Spine', 'Live2D'
    ]

    for kw in tool_keywords:
        if kw in text and kw not in skills['tools']:
            skills['tools'].append(kw)

    return skills


def extract_projects(text: str) -> List[Dict]:
    """æå–é¡¹ç›®ç»å†"""
    projects = []

    # é¡¹ç›®åˆ†å‰²æ¨¡å¼
    project_patterns = [
        r'(?:é¡¹ç›®ç»å†|é¡¹ç›®ç»éªŒ|Projects?)[ï¼š:\s]*\n?(.+?)(?=å·¥ä½œç»å†|æ•™è‚²èƒŒæ™¯|ä¸ªäººæŠ€èƒ½|$)',
    ]

    project_text = ""
    for pattern in project_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
        if match:
            project_text = match.group(1)
            break

    if not project_text:
        # å°è¯•ç›´æ¥æ‰¾é¡¹ç›®å…³é”®è¯
        project_text = text

    # å°è¯•è¯†åˆ«å•ä¸ªé¡¹ç›®ï¼ˆæŒ‰å¸¸è§åˆ†éš”ç¬¦åˆ†å‰²ï¼‰
    project_splits = re.split(r'\n(?=é¡¹ç›®\d+[ï¼š:]|ã€|â—†|â—|\d+\.)', project_text)

    for i, proj_text in enumerate(project_splits[:5]):  # æœ€å¤šå–5ä¸ªé¡¹ç›®
        if len(proj_text.strip()) < 20:
            continue

        # å°è¯•å¤šç§æ–¹å¼æå–é¡¹ç›®åç§°
        project_name = None

        # æ–¹å¼1ï¼šåŒ¹é… "é¡¹ç›®åç§°ï¼šXXX"ã€"é¡¹ç›®åï¼šXXX"ã€ã€ŠXXXã€‹ã€ã€XXXã€‘æ ¼å¼
        name_match = re.search(r'(?:é¡¹ç›®åç§°[ï¼š:]\s*|é¡¹ç›®å[ï¼š:]\s*|Project\s*Name[ï¼š:]\s*|ã€Š|ã€)([^\nã€ã€‘ã€‹]+)', proj_text, re.IGNORECASE)
        if name_match:
            project_name = name_match.group(1).strip()
        else:
            # æ–¹å¼2ï¼šå–é¡¹ç›®æ–‡æœ¬çš„ç¬¬ä¸€è¡Œä½œä¸ºé¡¹ç›®åï¼ˆå¦‚æœä¸æ˜¯åˆ†éš”ç¬¦ï¼‰
            first_line = proj_text.strip().split('\n')[0].strip()
            # è¿‡æ»¤æ‰çº¯æ•°å­—ã€åˆ†éš”ç¬¦ç­‰æ— æ„ä¹‰å†…å®¹
            if first_line and len(first_line) > 2 and len(first_line) < 50:
                # å»é™¤å¸¸è§çš„åˆ—è¡¨æ ‡è®°ï¼ˆå¦‚ "1. ", "- ", "â—† " ç­‰ï¼‰
                cleaned_name = re.sub(r'^[\d\s\.\-\â—†\â—\*\[\(]+', '', first_line)
                if cleaned_name and len(cleaned_name) > 2:
                    project_name = cleaned_name

        # ä½¿ç”¨æ™ºèƒ½æè¿°æå–
        meaningful_desc = extract_meaningful_description(proj_text)

        project = {
            'name': project_name or f'é¡¹ç›®{i+1}',
            'type': '',
            'role': '',
            'description': meaningful_desc,
            'tech_stack': []
        }

        # æå–é¡¹ç›®ç±»å‹
        if any(kw in proj_text for kw in ['2D', 'æ¨ªç‰ˆ', 'å¹³å°']):
            project['type'] = '2Dæ¨ªç‰ˆ/å¹³å°'
        elif any(kw in proj_text for kw in ['3D', 'ä¸‰ç»´']):
            project['type'] = '3Dæ¸¸æˆ'
        elif any(kw in proj_text for kw in ['FPS', 'å°„å‡»', 'ç¬¬ä¸€äººç§°']):
            project['type'] = 'FPSå°„å‡»'
        elif any(kw in proj_text for kw in ['RPG', 'è§’è‰²æ‰®æ¼”']):
            project['type'] = 'RPG'
        elif any(kw in proj_text for kw in ['å¯¹æˆ˜', 'PVP', 'MOBA']):
            project['type'] = 'ç½‘ç»œå¯¹æˆ˜'
        else:
            project['type'] = 'æ¸¸æˆé¡¹ç›®'

        # æå–è§’è‰²
        role_patterns = [
            r'(?:èŒè´£|è§’è‰²|æ‹…ä»»)[ï¼š:]\s*([^\n]+)',
            r'(ä¸»ç¨‹åº|å®¢æˆ·ç«¯|æœåŠ¡å™¨|ç‹¬ç«‹å¼€å‘|ç¨‹åº|ç­–åˆ’|ç¾æœ¯)',
        ]
        for pattern in role_patterns:
            role_match = re.search(pattern, proj_text)
            if role_match:
                project['role'] = role_match.group(1).strip()
                break

        # æå–æŠ€æœ¯æ ˆ
        tech_keywords = ['Unity', 'Unreal', 'UE4', 'UE5', 'C#', 'C++', 'Lua', 'Wwise', 'è¡Œä¸ºæ ‘', 'ECS']
        for tech in tech_keywords:
            if tech in proj_text:
                project['tech_stack'].append(tech)

        # æå–æŠ€æœ¯äº®ç‚¹
        tech_highlights = extract_tech_highlights(proj_text, project['tech_stack'])

        # æå–ä¸ªäººè´¡çŒ®ï¼ˆä¼ å…¥è§’è‰²ä¿¡æ¯ç”¨äºæ¨æ–­ï¼‰
        personal_contribution = extract_personal_contribution(proj_text, project['role'])

        # æå–é¡¹ç›®è¯¦ç»†ä¿¡æ¯
        project_details = extract_project_details(proj_text)
        project['project_scale'] = project_details.get('project_scale', '')
        project['development_time'] = project_details.get('development_time', '')
        project['team_size'] = project_details.get('team_size', '')
        project['core_systems'] = project_details.get('core_systems', [])
        project['tech_highlights'] = tech_highlights
        project['personal_contribution'] = personal_contribution

        # å¦‚æœæ ¸å¿ƒç³»ç»Ÿä¸ºç©ºï¼Œå°è¯•åŸºäºä¸Šä¸‹æ–‡æ¨æ–­
        if not project['core_systems']:
            inferred_systems = infer_core_systems_by_context(proj_text, project['role'], project['tech_stack'])
            if inferred_systems:
                project['core_systems'] = inferred_systems
                project['inferred_core_systems'] = True  # æ ‡è®°ä¸ºæ¨æ–­çš„

        # åˆ†æé¡¹ç›®å¤æ‚åº¦
        complexity_result = analyze_project_complexity(project)
        project['complexity_score'] = complexity_result['score']
        project['complexity_level'] = complexity_result['level']
        project['complexity_reason'] = complexity_result['reason']

        projects.append(project)

    return projects


def extract_project_details(proj_text: str) -> Dict:
    """
    æå–é¡¹ç›®è¯¦ç»†ä¿¡æ¯
    - å¼€å‘å‘¨æœŸã€å›¢é˜Ÿè§„æ¨¡
    - æ ¸å¿ƒç³»ç»Ÿï¼ˆæˆ˜æ–—ç³»ç»Ÿã€AIç³»ç»Ÿã€ç½‘ç»œåŒæ­¥ã€UIç³»ç»Ÿç­‰ï¼‰
    - é¡¹ç›®è§„æ¨¡æŒ‡æ ‡
    """
    details = {
        'project_scale': '',
        'development_time': '',
        'team_size': '',
        'core_systems': []
    }

    # æå–å¼€å‘å‘¨æœŸ
    time_patterns = [
        r'(?:å¼€å‘å‘¨æœŸ|é¡¹ç›®å‘¨æœŸ|æ—¶é—´)[ï¼š:]\s*([^\n]+)',
        r'(\d{4}[\.\-/]\d{1,2})\s*[-~è‡³]\s*(\d{4}[\.\-/]\d{1,2}|è‡³ä»Š)',
        r'(\d{4})\s*å¹´\s*(\d{1,2})\s*æœˆ\s*[-~è‡³]\s*(\d{4})\s*å¹´\s*(\d{1,2})\s*æœˆ',
        r'(\d{4}\.\d{1,2})\s*-\s*(\d{4}\.\d{1,2}|è‡³ä»Š)',
    ]
    for pattern in time_patterns:
        time_match = re.search(pattern, proj_text)
        if time_match:
            details['development_time'] = time_match.group(0).strip()
            break

    # æå–å›¢é˜Ÿè§„æ¨¡
    team_patterns = [
        r'(?:å›¢é˜Ÿè§„æ¨¡|å›¢é˜Ÿäººæ•°|å›¢é˜Ÿ)[ï¼š:]\s*(\d+)\s*äºº',
        r'å›¢é˜Ÿ\s*(\d+)\s*äºº',
        r'(\d+)\s*äººå›¢é˜Ÿ',
        r'(?:å›¢é˜Ÿ|é¡¹ç›®ç»„)(?:è§„æ¨¡)?[ï¼š:]?\s*(\d+)[\säºº]',
    ]
    for pattern in team_patterns:
        team_match = re.search(pattern, proj_text)
        if team_match:
            details['team_size'] = team_match.group(1) + 'äºº'
            break

    # æå–æ ¸å¿ƒç³»ç»Ÿ
    system_keywords = {
        'æˆ˜æ–—ç³»ç»Ÿ': ['æˆ˜æ–—ç³»ç»Ÿ', 'æˆ˜æ–—', 'æŠ€èƒ½ç³»ç»Ÿ', 'è¿æ‹›', 'æ‰“å‡»æ„Ÿ'],
        'AIç³»ç»Ÿ': ['AIç³»ç»Ÿ', 'è¡Œä¸ºæ ‘', 'çŠ¶æ€æœº', 'å¯»è·¯', 'Navigation', 'NPCè¡Œä¸º'],
        'ç½‘ç»œåŒæ­¥': ['ç½‘ç»œåŒæ­¥', 'å¸§åŒæ­¥', 'çŠ¶æ€åŒæ­¥', 'æœåŠ¡å™¨', 'è”æœº', 'å¤šäºº'],
        'UIç³»ç»Ÿ': ['UIç³»ç»Ÿ', 'ç•Œé¢', 'UGUI', 'FairyGUI', 'UIæ¡†æ¶'],
        'èµ„æºç®¡ç†': ['èµ„æºç®¡ç†', 'AssetBundle', 'Addressable', 'çƒ­æ›´æ–°', 'èµ„æºåŠ è½½'],
        'ç‰©ç†ç³»ç»Ÿ': ['ç‰©ç†ç³»ç»Ÿ', 'ç¢°æ’æ£€æµ‹', 'åˆšä½“', 'Physics'],
        'æ¸²æŸ“ç³»ç»Ÿ': ['æ¸²æŸ“', 'Shader', 'åå¤„ç†', 'å…‰ç…§', 'æè´¨'],
        'éŸ³é¢‘ç³»ç»Ÿ': ['éŸ³é¢‘', 'éŸ³æ•ˆ', 'Wwise', 'FMOD', 'å£°éŸ³'],
        'åŠ¨ç”»ç³»ç»Ÿ': ['åŠ¨ç”»', 'Animation', 'Animator', 'åŠ¨ä½œ', 'éª¨éª¼'],
        'å‰§æƒ…ç³»ç»Ÿ': ['å‰§æƒ…', 'å¯¹è¯ç³»ç»Ÿ', 'ä»»åŠ¡ç³»ç»Ÿ', 'å™äº‹'],
        'ç»æµç³»ç»Ÿ': ['ç»æµç³»ç»Ÿ', 'å•†åŸ', 'å……å€¼', 'è´§å¸'],
    }
    for system, keywords in system_keywords.items():
        if any(kw in proj_text for kw in keywords):
            details['core_systems'].append(system)

    # æå–é¡¹ç›®è§„æ¨¡
    scale_indicators = []
    if 'æ—¥æ´»' in proj_text or 'DAU' in proj_text or 'ç”¨æˆ·' in proj_text:
        scale_match = re.search(r'(?:æ—¥æ´»|DAU|ç”¨æˆ·)[ï¼š:]?\s*([\d\w]+)', proj_text)
        if scale_match:
            scale_indicators.append(f"ç”¨æˆ·è§„æ¨¡: {scale_match.group(1)}")
    if any(kw in proj_text for kw in ['åŒæ—¶åœ¨çº¿', 'å¹¶å‘']):
        scale_match = re.search(r'(?:åŒæ—¶åœ¨çº¿|å¹¶å‘)[ï¼š:]?\s*([\d\w]+)', proj_text)
        if scale_match:
            scale_indicators.append(f"å¹¶å‘: {scale_match.group(1)}")

    if scale_indicators:
        details['project_scale'] = 'ï¼Œ'.join(scale_indicators)

    return details


def infer_contribution_by_role(role: str) -> List[str]:
    """æ ¹æ®è§’è‰²æ¨æ–­å¯èƒ½çš„è´¡çŒ®"""
    role_contributions = {
        'å®¢æˆ·ç«¯': [
            'å‚ä¸æ¸¸æˆå®¢æˆ·ç«¯åŠŸèƒ½å¼€å‘',
            'è´Ÿè´£Gameplayç³»ç»Ÿå®ç°',
            'å‚ä¸UIäº¤äº’é€»è¾‘å¼€å‘',
            'ååŠ©èµ„æºç®¡ç†ä¸åŠ è½½ä¼˜åŒ–',
        ],
        'æœåŠ¡å™¨': [
            'å‚ä¸æœåŠ¡å™¨åç«¯å¼€å‘',
            'è´Ÿè´£ç½‘ç»œåŒæ­¥é€»è¾‘å®ç°',
            'å‚ä¸æ•°æ®å­˜å‚¨æ–¹æ¡ˆè®¾è®¡',
        ],
        'ä¸»ç¨‹åº': [
            'ä¸»å¯¼é¡¹ç›®æŠ€æœ¯æ¶æ„è®¾è®¡',
            'è´Ÿè´£æ ¸å¿ƒç³»ç»Ÿå¼€å‘',
            'æŒ‡å¯¼å›¢é˜Ÿæˆå‘˜å¼€å‘',
        ],
        'ç‹¬ç«‹å¼€å‘': [
            'ç‹¬ç«‹å®Œæˆé¡¹ç›®å…¨éƒ¨å¼€å‘å·¥ä½œ',
            'è´Ÿè´£æŠ€æœ¯é€‰å‹ä¸æ¶æ„è®¾è®¡',
            'å®Œæˆ gameplayã€UIã€ç³»ç»Ÿç­‰æ¨¡å—',
        ],
    }
    return role_contributions.get(role, [])


def infer_core_systems_by_context(proj_text: str, role: str, tech_stack: List[str]) -> List[str]:
    """åŸºäºä¸Šä¸‹æ–‡æ¨æ–­å¯èƒ½çš„æ ¸å¿ƒç³»ç»Ÿ"""
    inferred_systems = []

    # åŸºäºæŠ€æœ¯æ ˆæ¨æ–­
    if any(tech in proj_text for tech in ['Unity', 'unity']):
        inferred_systems.extend(['èµ„æºç®¡ç†', 'UIç³»ç»Ÿ', 'åŠ¨ç”»ç³»ç»Ÿ'])
    if any(tech in proj_text for tech in ['Wwise', 'wwise']):
        inferred_systems.append('éŸ³é¢‘ç³»ç»Ÿ')
    if 'ECS' in str(tech_stack):
        inferred_systems.append('ECSæ¶æ„ç³»ç»Ÿ')

    # åŸºäºè§’è‰²æ¨æ–­
    role_systems = {
        'å®¢æˆ·ç«¯': ['æ¸¸æˆç©æ³•ç³»ç»Ÿ', 'UIç³»ç»Ÿ', 'èµ„æºç®¡ç†'],
        'æœåŠ¡å™¨': ['ç½‘ç»œåŒæ­¥', 'æ•°æ®å­˜å‚¨', 'æœåŠ¡å™¨æ¶æ„'],
        'ä¸»ç¨‹åº': ['æ¶æ„è®¾è®¡', 'æ ¸å¿ƒç³»ç»Ÿ', 'æŠ€æœ¯æ¡†æ¶'],
    }
    if role in role_systems:
        inferred_systems.extend(role_systems[role])

    # åŸºäºæ–‡æœ¬å…³é”®è¯æ¨æ–­
    if any(kw in proj_text for kw in ['æ¸¸æˆ', 'ç©æ³•', 'æ“ä½œ', 'æˆ˜æ–—', 'æŠ€èƒ½']):
        inferred_systems.append('æ¸¸æˆç©æ³•ç³»ç»Ÿ')
    if any(kw in proj_text for kw in ['å·¥ä½œå®¤', 'å›¢é˜Ÿ', 'åä½œ', 'Git', 'SVN']):
        inferred_systems.append('ç‰ˆæœ¬æ§åˆ¶åä½œ')
    if any(kw in proj_text for kw in ['ç½‘ç»œ', 'è”æœº', 'å¤šäºº', 'åŒæ­¥']):
        inferred_systems.append('ç½‘ç»œåŒæ­¥ç³»ç»Ÿ')

    return list(set(inferred_systems))


def extract_meaningful_description(proj_text: str) -> str:
    """æå–æœ‰æ„ä¹‰çš„é¡¹ç›®æè¿°"""
    # 1. å°è¯•æ‰¾åˆ°"é¡¹ç›®æè¿°"ã€"é¡¹ç›®ä»‹ç»"ç­‰æ ‡ç­¾åçš„å†…å®¹
    desc_patterns = [
        r'(?:é¡¹ç›®æè¿°|é¡¹ç›®ä»‹ç»|é¡¹ç›®ç®€ä»‹|æè¿°)[ï¼š:]\s*([^\n]+(?:\n(?!(?:èŒè´£|è§’è‰²|æŠ€æœ¯|æˆæœ|æ‹…ä»»))[^\n]+)*)',
        r'(?:é¡¹ç›®èƒŒæ™¯|èƒŒæ™¯)[ï¼š:]\s*([^\n]+)',
    ]
    for pattern in desc_patterns:
        match = re.search(pattern, proj_text)
        if match:
            return match.group(1).strip()[:500]

    # 2. å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œå–éåˆ—è¡¨æ ‡è®°çš„ç¬¬ä¸€æ®µæœ‰æ„ä¹‰æ–‡å­—
    lines = proj_text.strip().split('\n')
    for line in lines:
        line = line.strip()
        # è¿‡æ»¤åˆ—è¡¨æ ‡è®°å’Œè¿‡çŸ­/è¿‡é•¿çš„è¡Œ
        if len(line) > 30 and len(line) < 300:
            if not re.match(r'^[-â€¢â—†â—\d\s\.\[\(]', line):
                return line[:500]

    # 3. å…œåº•ï¼šè¿”å›å‰500å­—ç¬¦
    return proj_text.strip()[:500]


def extract_tech_highlights(proj_text: str, tech_stack: List[str]) -> List[str]:
    """
    æå–æŠ€æœ¯äº®ç‚¹
    - è¯†åˆ«"å®ç°äº†/å¼€å‘äº†/è®¾è®¡äº†/ä¼˜åŒ–äº†"ç­‰å…³é”®è¯
    - æå–æ€§èƒ½æ•°æ®ï¼ˆæå‡X%ã€é™ä½Xæ¯«ç§’ï¼‰
    - è¯†åˆ«åˆ›æ–°ç‚¹ï¼ˆè‡ªå®šä¹‰ã€è‡ªç ”ã€ç‹¬åˆ›ï¼‰
    """
    highlights = []

    # æŠ€æœ¯å®ç°å…³é”®è¯ - æ‰©å±•åŒ¹é…æ¨¡å¼
    implementation_patterns = [
        # åŸæœ‰æ¨¡å¼
        r'(?:å®ç°äº†|å¼€å‘äº†|è®¾è®¡äº†|æ­å»ºäº†|å®Œæˆäº†|æ„å»ºäº†)([^ï¼Œã€‚\n]{5,100})',
        # æ–°å¢æ¨¡å¼ - æ³¨æ„è¿™é‡Œéœ€è¦åŒ¹é…"å®Œæˆäº†"è€Œä¸æ˜¯"å®Œæˆ"ï¼Œä»¥é¿å…åŒ¹é…"å®Œæˆ"å¼€å¤´çš„è¯ç»„
        r'(?:å®Œæˆäº†|å‚ä¸åˆ°|åˆ¶ä½œå‡º|ç¼–å†™å‡º|é‡æ„äº†|å°è£…äº†|é›†æˆäº†|éƒ¨ç½²äº†)([^ï¼Œã€‚\n]{5,100})',
        r'(?:ä½¿ç”¨|è¿ç”¨|åº”ç”¨|å€ŸåŠ©|é€šè¿‡)([^ï¼Œã€‚\n]{3,50})(?:å®Œæˆ|å®ç°|å¼€å‘|åˆ¶ä½œ|åšåˆ°)([^ï¼Œã€‚\n]{5,80})',
        r'(?:è§£å†³|å¤„ç†|å…‹æœ|åº”å¯¹)äº†?([^ï¼Œã€‚\n]{5,100})(?:é—®é¢˜|å›°éš¾|æŒ‘æˆ˜|bug|Bug)',
        r'(?:ä¼˜åŒ–|æ”¹è¿›|å®Œå–„|æå‡)äº†?([^ï¼Œã€‚\n]{5,100})',
        r'(?:ç‹¬ç«‹|è´Ÿè´£|ä¸»å¯¼)å®Œæˆ?äº†?([^ï¼Œã€‚\n]{5,100})',
    ]

    for pattern in implementation_patterns:
        matches = re.findall(pattern, proj_text)
        for match in matches:
            if isinstance(match, tuple):
                highlight = ''.join(match).strip()
            else:
                highlight = match.strip()
            if len(highlight) > 10 and len(highlight) < 150:
                # è¿‡æ»¤æ‰éæŠ€æœ¯æè¿°
                if any(tech in highlight for tech in tech_stack + ['ç³»ç»Ÿ', 'æ¡†æ¶', 'ä¼˜åŒ–', 'æ€§èƒ½', 'ç®—æ³•']):
                    highlights.append(highlight)

    # æå–æ€§èƒ½ä¼˜åŒ–æ•°æ®
    perf_patterns = [
        r'(?:æ€§èƒ½|æ•ˆç‡|å¸§ç‡|å†…å­˜|åŠ è½½)[^ï¼Œã€‚\n]*(?:æå‡|æé«˜|ä¼˜åŒ–|é™ä½|å‡å°‘)[^ï¼Œã€‚\n]*(?:\d+%?|\d+ms?|\d+ç§’?|X+å€?)',
        r'(?:æå‡|æé«˜|ä¼˜åŒ–|é™ä½|å‡å°‘)[^ï¼Œã€‚\n]*(?:\d+%?|\d+ms?|\d+ç§’?|X+å€?)[^ï¼Œã€‚\n]*(?:æ€§èƒ½|æ•ˆç‡|å¸§ç‡|å†…å­˜|åŠ è½½)',
        r'(?:å¸§ç‡|FPS)[^ï¼Œã€‚\n]*(?:æå‡|è¾¾åˆ°)[^ï¼Œã€‚\n]*\d+',
        r'(?:Draw ?Call|DC)[^ï¼Œã€‚\n]*(?:å‡å°‘|é™ä½|ä¼˜åŒ–)[^ï¼Œã€‚\n]*\d+',
    ]
    for pattern in perf_patterns:
        perf_matches = re.findall(pattern, proj_text, re.IGNORECASE)
        for match in perf_matches:
            highlight = match.strip()
            if highlight and highlight not in highlights:
                highlights.append(f"æ€§èƒ½ä¼˜åŒ–: {highlight}")

    # æå–åˆ›æ–°ç‚¹
    innovation_keywords = ['è‡ªå®šä¹‰', 'è‡ªç ”', 'ç‹¬åˆ›', 'è‡ªä¸»ç ”å‘', 'ä»é›¶æ­å»º', 'æ¶æ„è®¾è®¡']
    for keyword in innovation_keywords:
        pattern = rf'{keyword}([^ï¼Œã€‚\n]{{5,80}})'
        matches = re.findall(pattern, proj_text)
        for match in matches:
            highlight = f"{keyword}{match.strip()}"
            if highlight not in highlights:
                highlights.append(highlight)

    # å»é‡å¹¶é™åˆ¶æ•°é‡
    unique_highlights = []
    for h in highlights:
        h_clean = re.sub(r'\s+', '', h)
        if not any(re.sub(r'\s+', '', existing) == h_clean for existing in unique_highlights):
            unique_highlights.append(h)

    return unique_highlights[:6]  # æœ€å¤šè¿”å›6ä¸ªäº®ç‚¹


def extract_personal_contribution(proj_text: str, role: str = '') -> List[str]:
    """
    æå–ä¸ªäººè´¡çŒ®
    - è¯†åˆ«"è´Ÿè´£/ä¸»å¯¼/ç‹¬ç«‹/å‚ä¸"ç­‰èŒè´£æè¿°
    - æå–ç¬¬ä¸€äººç§°æè¿°
    - è¯†åˆ«å…·ä½“æˆæœæ•°æ®
    - æ–°å¢ï¼šåŸºäºè§’è‰²çš„æ¨æ–­
    """
    contributions = []

    # èŒè´£æè¿°æ¨¡å¼ - æ‰©å±•æ¨¡å¼
    responsibility_patterns = [
        # åŸæœ‰æ¨¡å¼
        r'(?:è´Ÿè´£|ä¸»å¯¼|ç‹¬ç«‹|å¸¦é¢†|å‚ä¸|ååŠ©|é…åˆ)äº†?([^ï¼Œã€‚ï¼š\n]{5,100})',
        r'(?:æˆ‘|æœ¬äºº)(?:è´Ÿè´£|ä¸»å¯¼|ç‹¬ç«‹|å‚ä¸|å®Œæˆ|å®ç°)äº†?([^ï¼Œã€‚ï¼š\n]{5,100})',
        r'(?:æ‹…ä»»|ä½œä¸º)([^ï¼Œã€‚ï¼š\n]{3,20})(?:è´Ÿè´£|ä¸»å¯¼|å‚ä¸)äº†?([^ï¼Œã€‚ï¼š\n]{5,80})',
        # æ–°å¢æ¨¡å¼ - åŒ¹é…æ›´è‡ªç„¶çš„æè¿°
        r'(?:å‚ä¸|åä½œ|é…åˆ)äº†?([^ï¼Œã€‚ï¼š\n]{5,100})',
        r'(?:å­¦ä¹ |æŒæ¡|ç†Ÿæ‚‰|äº†è§£)äº†?([^ï¼Œã€‚ï¼š\n]{5,60})(?:æŠ€æœ¯|å·¥å…·|æŠ€èƒ½|æ¡†æ¶)',
        r'(?:ç§¯ç´¯|æ²‰æ·€|æ€»ç»“)äº†?([^ï¼Œã€‚ï¼š\n]{5,80})(?:ç»éªŒ|èƒ½åŠ›|çŸ¥è¯†)',
    ]

    for pattern in responsibility_patterns:
        matches = re.findall(pattern, proj_text)
        for match in matches:
            if isinstance(match, tuple):
                contribution = ''.join(match).strip()
            else:
                contribution = match.strip()
            if len(contribution) > 5 and len(contribution) < 120:
                contributions.append(contribution)

    # æå–å…·ä½“æˆæœï¼ˆåŒ…å«æ•°å­—ï¼‰
    achievement_patterns = [
        r'(?:å®Œæˆ|å®ç°|äº¤ä»˜|ä¸Šçº¿)[^ï¼Œã€‚\n]*(?:\d+)[^ï¼Œã€‚\n]*(?:ä¸ª|é¡¹|å¥—|ç‰ˆ|åŠŸèƒ½|æ¨¡å—|ç³»ç»Ÿ)',
        r'(?:ä¼˜åŒ–|æ”¹è¿›)[^ï¼Œã€‚\n]*(?:\d+)[^ï¼Œã€‚\n]*(?:å¤„|ä¸ª|é¡¹|é—®é¢˜|Bug)',
        r'(?:èŠ‚çº¦|èŠ‚çœ|å‡å°‘)[^ï¼Œã€‚\n]*(?:\d+)[^ï¼Œã€‚\n]*(?:æ—¶é—´|æˆæœ¬|äººåŠ›|èµ„æº)',
    ]
    for pattern in achievement_patterns:
        matches = re.findall(pattern, proj_text)
        for match in matches:
            if match.strip() and match.strip() not in contributions:
                contributions.append(match.strip())

    # å»é‡
    unique_contributions = []
    for c in contributions:
        c_clean = re.sub(r'\s+', '', c)
        if not any(re.sub(r'\s+', '', existing) == c_clean for existing in unique_contributions):
            unique_contributions.append(c)

    # å¦‚æœè§„åˆ™æå–ä¸åˆ°å†…å®¹ï¼Œå°è¯•åŸºäºè§’è‰²æ¨æ–­
    if not unique_contributions and role:
        inferred = infer_contribution_by_role(role)
        if inferred:
            # æ·»åŠ æ¨æ–­æ ‡è®°
            unique_contributions = [f"[åŸºäºè§’è‰²æ¨æ–­] {c}" for c in inferred[:2]]

    return unique_contributions[:5]  # æœ€å¤šè¿”å›5ä¸ªè´¡çŒ®ç‚¹


def analyze_project_complexity(project: Dict) -> Dict:
    """
    åŸºäºå¤šç»´åº¦è¯„ä¼°é¡¹ç›®å¤æ‚åº¦
    - æŠ€æœ¯æ ˆä¸°å¯Œåº¦ (20%)
    - ç³»ç»Ÿå¤æ‚åº¦ (25%)
    - é¡¹ç›®è§„æ¨¡ (20%)
    - æŠ€æœ¯äº®ç‚¹ (20%)
    - æè¿°å®Œæ•´åº¦ (15%)
    è¿”å›å¤æ‚åº¦ç­‰çº§å’Œè¯„ä¼°ç†ç”±
    """
    score = 0
    reasons = []

    # 1. æŠ€æœ¯æ ˆä¸°å¯Œåº¦ (æœ€é«˜20åˆ†)
    tech_count = len(project.get('tech_stack', []))
    if tech_count >= 5:
        score += 20
        reasons.append('æŠ€æœ¯æ ˆä¸°å¯Œ')
    elif tech_count >= 3:
        score += 15
        reasons.append('æŠ€æœ¯æ ˆè¾ƒä¸°å¯Œ')
    elif tech_count >= 1:
        score += 8
    else:
        reasons.append('æŠ€æœ¯æ ˆå•ä¸€')

    # 2. ç³»ç»Ÿå¤æ‚åº¦ (æœ€é«˜25åˆ†)
    core_systems = project.get('core_systems', [])
    system_count = len(core_systems)
    if system_count >= 4:
        score += 25
        reasons.append(f'æ¶‰åŠ{system_count}ä¸ªæ ¸å¿ƒç³»ç»Ÿ')
    elif system_count >= 2:
        score += 18
        reasons.append(f'æ¶‰åŠ{system_count}ä¸ªæ ¸å¿ƒç³»ç»Ÿ')
    elif system_count >= 1:
        score += 10
    else:
        reasons.append('æœªæ˜ç¡®æ ¸å¿ƒç³»ç»Ÿ')

    # 3. é¡¹ç›®è§„æ¨¡ (æœ€é«˜20åˆ†)
    scale_score = 0
    team_size = project.get('team_size', '')
    if team_size:
        team_num = re.search(r'(\d+)', team_size)
        if team_num:
            num = int(team_num.group(1))
            if num >= 10:
                scale_score = 20
                reasons.append('å›¢é˜Ÿè§„æ¨¡è¾ƒå¤§')
            elif num >= 5:
                scale_score = 15
            elif num >= 3:
                scale_score = 10
            else:
                scale_score = 5

    dev_time = project.get('development_time', '')
    if dev_time and ('å¹´' in dev_time or re.search(r'\d+\s*ä¸ªæœˆ', dev_time)):
        if scale_score < 15:
            scale_score = 15
        if 'å¼€å‘å‘¨æœŸé•¿' not in reasons:
            reasons.append('å¼€å‘å‘¨æœŸè¾ƒé•¿')

    score += scale_score

    # 4. æŠ€æœ¯äº®ç‚¹ (æœ€é«˜20åˆ†)
    highlights = project.get('tech_highlights', [])
    highlight_count = len(highlights)
    if highlight_count >= 4:
        score += 20
        reasons.append('æŠ€æœ¯äº®ç‚¹çªå‡º')
    elif highlight_count >= 2:
        score += 15
        reasons.append('æœ‰æŠ€æœ¯äº®ç‚¹')
    elif highlight_count >= 1:
        score += 8
    else:
        reasons.append('ç¼ºå°‘æŠ€æœ¯äº®ç‚¹æè¿°')

    # 5. æè¿°å®Œæ•´åº¦ (æœ€é«˜15åˆ†)
    desc_len = len(project.get('description', ''))
    if desc_len >= 400:
        score += 15
    elif desc_len >= 200:
        score += 10
        if desc_len < 300:
            reasons.append('é¡¹ç›®æè¿°å¯æ›´è¯¦ç»†')
    elif desc_len >= 100:
        score += 5
        reasons.append('é¡¹ç›®æè¿°è¾ƒç®€å•')
    else:
        score += 2
        reasons.append('é¡¹ç›®æè¿°è¿‡äºç®€å•')

    # ç¡®å®šå¤æ‚åº¦ç­‰çº§
    if score >= 75:
        level = 'é«˜'
    elif score >= 50:
        level = 'ä¸­ç­‰'
    elif score >= 30:
        level = 'ä¸€èˆ¬'
    else:
        level = 'å…¥é—¨'

    # ç”Ÿæˆè¯„ä¼°ç†ç”±
    if reasons:
        reason_text = 'ï¼Œ'.join(reasons[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªç†ç”±
    else:
        reason_text = 'é¡¹ç›®ä¿¡æ¯å®Œæ•´åº¦ä¸€èˆ¬'

    return {
        'score': min(score, 100),
        'level': level,
        'reason': reason_text
    }


def extract_work_experience(text: str) -> List[str]:
    """æå–å·¥ä½œç»å†"""
    experiences = []

    patterns = [
        r'(?:å·¥ä½œç»å†|å·¥ä½œç»éªŒ|Work Experience)[ï¼š:\s]*\n?(.+?)(?=é¡¹ç›®ç»å†|æ•™è‚²èƒŒæ™¯|ä¸ªäººæŠ€èƒ½|$)',
    ]

    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
        if match:
            exp_text = match.group(1).strip()
            # ç®€å•æŒ‰è¡Œåˆ†å‰²
            lines = [line.strip() for line in exp_text.split('\n') if line.strip()]
            return lines[:5]  # æœ€å¤š5æ¡

    return experiences


def analyze_skills(parsed_data: Dict) -> Dict:
    """
    åˆ†ææŠ€èƒ½ç†Ÿç»ƒåº¦å’Œé£é™©ç‚¹

    è¿”å›åˆ†æç»“æœï¼š
    {
        'skill_levels': List[Dict],
        'advantages': List[str],
        'risks': List[str],
        'recommendation_level': str,
        'overall_assessment': str,
        'suitable_positions': List[str]
    }
    """
    analysis = {
        'skill_levels': [],
        'advantages': [],
        'risks': [],
        'recommendation_level': 'B',
        'overall_assessment': '',
        'suitable_positions': []
    }

    skills = parsed_data['skills']
    projects = parsed_data['projects']

    # åˆ†ææŠ€èƒ½ç†Ÿç»ƒåº¦
    all_skills = []
    all_skills.extend([(s, 'ç¼–ç¨‹è¯­è¨€') for s in skills['languages']])
    all_skills.extend([(s, 'æ¸¸æˆå¼•æ“') for s in skills['engines']])
    all_skills.extend([(s, 'ä¸“ä¸šæŠ€èƒ½') for s in skills['professional']])
    all_skills.extend([(s, 'å·¥å…·') for s in skills['tools']])

    for skill, category in all_skills:
        level = 'äº†è§£'
        evidence = 'ç®€å†æåŠ'

        # æ ¹æ®é¡¹ç›®æ•°é‡åˆ¤æ–­ç†Ÿç»ƒåº¦
        related_projects = sum(1 for p in projects if skill in str(p))
        if related_projects >= 2:
            level = 'ç²¾é€š'
            evidence = f'{related_projects}ä¸ªé¡¹ç›®ç»éªŒ'
        elif related_projects == 1:
            level = 'ç†Ÿç»ƒ'
            evidence = '1ä¸ªé¡¹ç›®ç»éªŒ'
        elif len(projects) > 0:
            level = 'äº†è§£'
            evidence = 'ç®€å†æåŠ'

        analysis['skill_levels'].append({
            'skill': skill,
            'category': category,
            'level': level,
            'evidence': evidence
        })

    # ç”Ÿæˆä¼˜åŠ¿äº®ç‚¹
    advantages = []

    # å¼•æ“ç»éªŒ
    if 'Unity' in skills['engines']:
        advantages.append('å…·å¤‡Unityå¼•æ“å¼€å‘ç»éªŒ')
    if 'Unreal Engine' in skills['engines']:
        advantages.append('å…·å¤‡Unreal Engineå¼€å‘ç»éªŒ')

    # ç¼–ç¨‹è¯­è¨€
    if 'C#' in skills['languages'] and 'C++' in skills['languages']:
        advantages.append('åŒæ—¶æŒæ¡C#å’ŒC++ï¼Œè¯­è¨€åŸºç¡€æ‰å®')

    # é¡¹ç›®ç»éªŒ
    if len(projects) >= 2:
        advantages.append(f'æœ‰{len(projects)}ä¸ªé¡¹ç›®ç»å†ï¼Œé¡¹ç›®ç»éªŒä¸°å¯Œ')

    # ç‰¹æ®ŠæŠ€èƒ½
    advanced_skills = ['ECS', 'Shader', 'ç½‘ç»œ', 'AI', 'æ€§èƒ½ä¼˜åŒ–']
    for skill in advanced_skills:
        if any(skill in s for s in skills['professional']):
            advantages.append(f'å…·å¤‡{skill}ç›¸å…³ç»éªŒ')
            break

    if not advantages:
        advantages.append('åŸºç¡€æŠ€èƒ½ç¬¦åˆå²—ä½è¦æ±‚')

    analysis['advantages'] = advantages

    # ç”Ÿæˆé£é™©ç‚¹
    risks = []

    # æ£€æŸ¥æŠ€èƒ½ç»„åˆæ˜¯å¦åˆç†
    if 'Unity' in str(skills['engines']) and 'C#' not in str(skills['languages']):
        risks.append('Unityç»éªŒä½†æœªè§C#æŠ€èƒ½ï¼Œéœ€éªŒè¯å®é™…ä½¿ç”¨ç¨‹åº¦')

    if 'Unreal Engine' in str(skills['engines']) and 'C++' not in str(skills['languages']):
        risks.append('Unrealç»éªŒä½†æœªè§C++æŠ€èƒ½ï¼Œéœ€ç¡®è®¤ä½¿ç”¨ç‰ˆæœ¬å’Œæ·±åº¦')

    # é¡¹ç›®æè¿°ç®€å•
    if projects:
        avg_desc_len = sum(len(p['description']) for p in projects) / len(projects)
        if avg_desc_len < 100:
            risks.append('é¡¹ç›®æè¿°è¾ƒä¸ºç®€å•ï¼Œéœ€æ·±å…¥äº†è§£é¡¹ç›®ç»†èŠ‚å’ŒæŠ€æœ¯éš¾ç‚¹')

    # ç¼ºå°‘æ ¸å¿ƒæŠ€æœ¯
    if not any(kw in str(skills['professional']) for kw in ['è®¾è®¡æ¨¡å¼', 'æ¶æ„']):
        risks.append('æœªè§æ¶æ„/è®¾è®¡æ¨¡å¼ç›¸å…³ç»éªŒï¼Œéœ€éªŒè¯ä»£ç ç»„ç»‡èƒ½åŠ›')

    if not risks:
        risks.append('éœ€è¿›ä¸€æ­¥é¢è¯•éªŒè¯æŠ€æœ¯æ·±åº¦')

    analysis['risks'] = risks

    # æ¨èç­‰çº§
    if len(projects) >= 3 and len(skills['languages']) >= 2:
        analysis['recommendation_level'] = 'A'
        analysis['overall_assessment'] = 'é¡¹ç›®ç»éªŒä¸°å¯Œï¼ŒæŠ€æœ¯æ ˆå…¨é¢ï¼Œå¼ºçƒˆæ¨è'
    elif len(projects) >= 2:
        analysis['recommendation_level'] = 'B'
        analysis['overall_assessment'] = 'é¡¹ç›®ç»éªŒè‰¯å¥½ï¼Œå…·å¤‡å²—ä½æ‰€éœ€åŸºç¡€èƒ½åŠ›'
    elif len(projects) >= 1:
        analysis['recommendation_level'] = 'C'
        analysis['overall_assessment'] = 'é¡¹ç›®ç»éªŒæœ‰é™ï¼Œéœ€è°¨æ…è¯„ä¼°å®é™…èƒ½åŠ›'
    else:
        analysis['recommendation_level'] = 'D'
        analysis['overall_assessment'] = 'é¡¹ç›®ç»éªŒä¸è¶³ï¼Œå»ºè®®äº†è§£å­¦ä¹ èƒ½åŠ›å’Œæ½œåŠ›'

    # é€‚åˆå²—ä½
    if 'Unity' in str(skills['engines']):
        analysis['suitable_positions'].append('Unityæ¸¸æˆå¼€å‘å·¥ç¨‹å¸ˆ')
    if 'Unreal Engine' in str(skills['engines']):
        analysis['suitable_positions'].append('UE4/UE5æ¸¸æˆå¼€å‘å·¥ç¨‹å¸ˆ')
    if not analysis['suitable_positions']:
        analysis['suitable_positions'].append('æ¸¸æˆå¼€å‘å·¥ç¨‹å¸ˆ')

    return analysis


def generate_skill_report(parsed_data: Dict, analysis: Dict, output_dir: str) -> str:
    """ç”ŸæˆæŠ€èƒ½è¯„ä¼°æŠ¥å‘Š"""
    name = parsed_data['name']
    today = datetime.now().strftime('%Y%m%d')

    lines = []
    lines.append(f"# å€™é€‰äººæŠ€èƒ½è¯„ä¼°æŠ¥å‘Š - {name}")
    lines.append("")

    # åŸºæœ¬ä¿¡æ¯
    lines.append("## åŸºæœ¬ä¿¡æ¯")
    lines.append("")
    lines.append("| é¡¹ç›® | å†…å®¹ |")
    lines.append("|------|------|")
    lines.append(f"| å§“å | {name} |")
    lines.append(f"| æœŸæœ›å²—ä½ | {parsed_data['position']} |")
    lines.append(f"| å·¥ä½œå¹´é™ | {parsed_data['experience_years']} |")
    lines.append(f"| æ¯•ä¸šé™¢æ ¡ | {parsed_data['education'] or 'æœªè¯†åˆ«'} |")
    lines.append("")

    # æŠ€èƒ½æ¦‚è§ˆ
    lines.append("## æŠ€èƒ½æ¦‚è§ˆ")
    lines.append("")

    skills = parsed_data['skills']

    lines.append("### æŠ€æœ¯æ ˆ")
    lines.append("")
    if skills['languages']:
        lines.append(f"- **ç¼–ç¨‹è¯­è¨€**: {', '.join(skills['languages'])}")
    if skills['engines']:
        lines.append(f"- **æ¸¸æˆå¼•æ“**: {', '.join(skills['engines'])}")
    if skills['professional']:
        prof_str = ', '.join(skills['professional'][:10])  # æœ€å¤šæ˜¾ç¤º10ä¸ª
        lines.append(f"- **ä¸“ä¸šæŠ€èƒ½**: {prof_str}")
    if skills['tools']:
        tools_str = ', '.join(skills['tools'][:8])  # æœ€å¤šæ˜¾ç¤º8ä¸ª
        lines.append(f"- **å·¥å…·**: {tools_str}")
    lines.append("")

    # æŠ€èƒ½ç†Ÿç»ƒåº¦è¯„ä¼°
    lines.append("### æŠ€èƒ½ç†Ÿç»ƒåº¦è¯„ä¼°")
    lines.append("")
    lines.append("| æŠ€èƒ½ | ç†Ÿç»ƒåº¦ | è¯æ®æ¥æº |")
    lines.append("|------|--------|----------|")

    for item in analysis['skill_levels'][:15]:  # æœ€å¤šæ˜¾ç¤º15ä¸ª
        lines.append(f"| {item['skill']} | {item['level']} | {item['evidence']} |")
    lines.append("")

    # é¡¹ç›®ç»å†åˆ†æ
    lines.append("## é¡¹ç›®ç»å†åˆ†æ")
    lines.append("")

    for i, project in enumerate(parsed_data['projects'][:3], 1):  # æœ€å¤š3ä¸ªé¡¹ç›®
        lines.append(f"### é¡¹ç›®{i}: {project['name']}")
        lines.append(f"- **é¡¹ç›®ç±»å‹**: {project.get('type', 'æ¸¸æˆé¡¹ç›®')}")
        lines.append(f"- **æ‹…ä»»è§’è‰²**: {project.get('role') or 'æœªæ˜ç¡®'}")

        # å›¢é˜Ÿè§„æ¨¡å’Œå¼€å‘å‘¨æœŸ
        if project.get('team_size'):
            lines.append(f"- **å›¢é˜Ÿè§„æ¨¡**: {project['team_size']}")
        if project.get('development_time'):
            lines.append(f"- **å¼€å‘å‘¨æœŸ**: {project['development_time']}")

        # é¡¹ç›®è§„æ¨¡
        if project.get('project_scale'):
            lines.append(f"- **é¡¹ç›®è§„æ¨¡**: {project['project_scale']}")

        lines.append("")

        # é¡¹ç›®æè¿°ï¼ˆæˆªå–å‰200å­—ç¬¦ï¼‰
        desc = project.get('description', '')
        if desc:
            desc_short = desc[:200] + '...' if len(desc) > 200 else desc
            lines.append(f"**é¡¹ç›®æè¿°**: {desc_short}")
            lines.append("")

        # æŠ€æœ¯æ ˆ
        if project.get('tech_stack'):
            lines.append(f"- **æŠ€æœ¯æ ˆ**: {', '.join(project['tech_stack'])}")

        # æ ¸å¿ƒç³»ç»Ÿ
        if project.get('core_systems'):
            systems_str = ', '.join(project['core_systems'])
            if project.get('inferred_core_systems'):
                lines.append(f"- **æ ¸å¿ƒç³»ç»Ÿ**ï¼ˆæ¨æ–­ï¼‰: {systems_str}")
            else:
                lines.append(f"- **æ ¸å¿ƒç³»ç»Ÿ**: {systems_str}")

        lines.append("")

        # æŠ€æœ¯äº®ç‚¹
        tech_highlights = project.get('tech_highlights', [])
        if tech_highlights:
            lines.append("**æŠ€æœ¯äº®ç‚¹**:")
            for highlight in tech_highlights[:4]:  # æœ€å¤šæ˜¾ç¤º4ä¸ªäº®ç‚¹
                lines.append(f"  - {highlight}")
            lines.append("")

        # ä¸ªäººè´¡çŒ®
        contributions = project.get('personal_contribution', [])
        if contributions:
            lines.append("**ä¸ªäººè´¡çŒ®**:")
            for contrib in contributions[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªè´¡çŒ®ç‚¹
                lines.append(f"  - {contrib}")
            lines.append("")

        # å¤æ‚åº¦è¯„ä¼°
        complexity_level = project.get('complexity_level', 'æœªçŸ¥')
        complexity_reason = project.get('complexity_reason', '')
        lines.append(f"- **å¤æ‚åº¦è¯„ä¼°**: {complexity_level}")
        if complexity_reason:
            lines.append(f"- **è¯„ä¼°ç†ç”±**: {complexity_reason}")

        # é£é™©ç‚¹
        risks = []
        follow_up_questions = []

        if not project.get('role'):
            risks.append('èŒè´£æè¿°ä¸æ¸…æ™°ï¼Œå»ºè®®è¿½é—®å…·ä½“åˆ†å·¥')
            follow_up_questions.append('ä½ åœ¨é¡¹ç›®ä¸­å…·ä½“æ‹…ä»»ä»€ä¹ˆè§’è‰²ï¼Ÿè´Ÿè´£å“ªäº›æ¨¡å—ï¼Ÿ')

        if len(desc) < 100:
            risks.append('é¡¹ç›®æè¿°è¾ƒç®€å•ï¼Œå»ºè®®æ·±å…¥äº†è§£æŠ€æœ¯ç»†èŠ‚')
            follow_up_questions.append('è¯·è¯¦ç»†æè¿°é¡¹ç›®çš„æŠ€æœ¯æ¶æ„å’Œå®ç°æ–¹æ¡ˆ')

        if not tech_highlights:
            risks.append('æœªæ˜ç¡®æŠ€æœ¯äº®ç‚¹ï¼Œå»ºè®®è¯¢é—®é‡åˆ°çš„æŠ€æœ¯éš¾ç‚¹å’Œè§£å†³æ–¹æ¡ˆ')
            follow_up_questions.append('é¡¹ç›®å¼€å‘ä¸­é‡åˆ°è¿‡å“ªäº›æŠ€æœ¯æŒ‘æˆ˜ï¼Ÿå¦‚ä½•è§£å†³çš„ï¼Ÿ')

        if not contributions:
            risks.append('ä¸ªäººè´¡çŒ®ä¸çªå‡ºï¼Œå»ºè®®è¿½é—®å…·ä½“è´Ÿè´£çš„å·¥ä½œå†…å®¹')
            follow_up_questions.append('åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ä½ å…·ä½“å®Œæˆäº†å“ªäº›å·¥ä½œï¼Ÿ')

        if project.get('inferred_core_systems'):
            risks.append('æ ¸å¿ƒç³»ç»Ÿæœªæ˜ç¡®ï¼Œå»ºè®®æ ¸å®å®é™…å‚ä¸çš„ç³»ç»Ÿ')

        if risks:
            lines.append(f"- **é£é™©ç‚¹**: {'; '.join(risks)}")

        # æ·»åŠ å»ºè®®è¿½é—®é—®é¢˜
        if follow_up_questions and not tech_highlights:
            lines.append("- **å»ºè®®è¿½é—®**:")
            for q in follow_up_questions[:2]:
                lines.append(f"  - {q}")

        lines.append("")

    # ä¼˜åŠ¿äº®ç‚¹
    lines.append("## ä¼˜åŠ¿äº®ç‚¹")
    lines.append("")
    for i, adv in enumerate(analysis['advantages'], 1):
        lines.append(f"{i}. {adv}")
    lines.append("")

    # é£é™©ç‚¹
    lines.append("## é£é™©ç‚¹/å¾…éªŒè¯")
    lines.append("")
    for i, risk in enumerate(analysis['risks'], 1):
        lines.append(f"{i}. {risk}")
    lines.append("")

    # ç»¼åˆè¯„ä»·
    lines.append("## ç»¼åˆè¯„ä»·")
    lines.append("")
    lines.append(f"- **æ¨èç­‰çº§**: {analysis['recommendation_level']}çº§")
    lines.append(f"- **æ€»ä½“è¯„ä»·**: {analysis['overall_assessment']}")
    lines.append(f"- **é€‚åˆå²—ä½**: {', '.join(analysis['suitable_positions'])}")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append(f"*æŠ¥å‘Šç”±ç®€å†è‡ªåŠ¨åˆ†æç³»ç»Ÿç”Ÿæˆ*")
    lines.append(f"*ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

    content = "\n".join(lines)

    # ä¿å­˜æ–‡ä»¶
    filename = f"æŠ€èƒ½è¯„ä¼°æŠ¥å‘Š_{name}_{today}.md"
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        filepath = os.path.join(output_dir, filename)
    else:
        filepath = filename

    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)

    return filepath


def generate_question_list(parsed_data: Dict, analysis: Dict, output_dir: str) -> str:
    """ç”Ÿæˆé¢è¯•é—®é¢˜æ¸…å•"""
    name = parsed_data['name']
    today = datetime.now().strftime('%Y%m%d')
    skills = parsed_data['skills']
    projects = parsed_data['projects']

    lines = []
    lines.append(f"# é¢è¯•é—®é¢˜æ¸…å• - {name}")
    lines.append("")

    # é¢è¯•æ¦‚è§ˆ
    lines.append("## é¢è¯•æ¦‚è§ˆ")
    lines.append(f"- **å€™é€‰äºº**: {name}")
    lines.append(f"- **å²—ä½**: {parsed_data['position']}")
    lines.append(f"- **å»ºè®®æ—¶é•¿**: 30-35åˆ†é’Ÿ")
    lines.append("")

    # é˜¶æ®µ1: è‡ªæˆ‘ä»‹ç»
    lines.append("## é˜¶æ®µ1: è‡ªæˆ‘ä»‹ç» (2åˆ†é’Ÿ)")
    lines.append("- [ ] è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±")
    lines.append("- [ ] ä¸ºä»€ä¹ˆæ¥é¢è¯•è¿™ä¸ªå²—ä½ï¼Ÿ")
    lines.append("- [ ] ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬å…¬å¸/é¡¹ç›®ç»„ï¼Ÿ")
    lines.append("")

    # é˜¶æ®µ2: é¡¹ç›®ç»å†æ·±æŒ–
    lines.append("## é˜¶æ®µ2: é¡¹ç›®ç»å†æ·±æŒ– (20åˆ†é’Ÿ)")
    lines.append("")

    for i, project in enumerate(projects[:3], 1):
        lines.append(f"### é¡¹ç›®{i}: {project['name']}")
        lines.append("")

        # æ¶æ„é—®é¢˜
        lines.append("**æ¶æ„ä¸è®¾è®¡**:")
        lines.append(f"- [ ] è¯·ä»‹ç»ä¸€ä¸‹ã€Š{project['name']}ã€‹çš„æ•´ä½“æ¶æ„")
        lines.append(f"- [ ] ä½ åœ¨é¡¹ç›®ä¸­æ‹…ä»»{project['role'] or 'ä»€ä¹ˆè§’è‰²'}ï¼Ÿå›¢é˜Ÿè§„æ¨¡ï¼Ÿ")
        lines.append(f"- [ ] é¡¹ç›®çš„æ ¸å¿ƒç©æ³•æ˜¯ä»€ä¹ˆï¼ŸæŠ€æœ¯æŒ‘æˆ˜åœ¨å“ªé‡Œï¼Ÿ")
        lines.append("")

        # æŠ€æœ¯ç»†èŠ‚é—®é¢˜ï¼ˆåŸºäºæŠ€æœ¯æ ˆï¼‰
        if project['tech_stack']:
            lines.append("**æŠ€æœ¯ç»†èŠ‚**:")
            for tech in project['tech_stack'][:3]:
                if tech == 'Unity':
                    lines.append(f"- [ ] [{tech}] é¡¹ç›®ä¸­ä½¿ç”¨äº†Unityçš„å“ªäº›ç³»ç»Ÿï¼Ÿ")
                    lines.append(f"- [ ] [{tech}] èµ„æºç®¡ç†æ˜¯å¦‚ä½•åšçš„ï¼Ÿ")
                elif tech == 'Wwise':
                    lines.append(f"- [ ] [{tech}] Wwiseä¸UnityéŸ³é¢‘ç³»ç»Ÿçš„åŒºåˆ«ï¼Ÿ")
                elif tech == 'è¡Œä¸ºæ ‘':
                    lines.append(f"- [ ] [{tech}] AIçš„è¡Œä¸ºæ ‘æ˜¯å¦‚ä½•è®¾è®¡çš„ï¼Ÿ")
                else:
                    lines.append(f"- [ ] [{tech}] å¦‚ä½•ä½¿ç”¨{tech}è§£å†³å…·ä½“é—®é¢˜ï¼Ÿ")
            lines.append("")

        # æŒ‘æˆ˜ä¸è§£å†³
        lines.append("**æŒ‘æˆ˜ä¸è§£å†³**:")
        lines.append("- [ ] é¡¹ç›®ä¸­é‡åˆ°çš„æœ€å¤§æŠ€æœ¯æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•è§£å†³çš„ï¼Ÿ")
        lines.append("- [ ] å¦‚æœé‡æ–°è®¾è®¡è¿™ä¸ªé¡¹ç›®ï¼Œä¼šåšå“ªäº›æ”¹è¿›ï¼Ÿ")
        lines.append("- [ ] å¦‚ä½•ä¿è¯ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§ï¼Ÿ")
        lines.append("")

    # é˜¶æ®µ3: åŸºç¡€èƒ½åŠ›è€ƒå¯Ÿ
    lines.append("## é˜¶æ®µ3: åŸºç¡€èƒ½åŠ›è€ƒå¯Ÿ (5åˆ†é’Ÿ)")
    lines.append("")

    # æ ¹æ®æŠ€èƒ½ç”Ÿæˆé’ˆå¯¹æ€§é—®é¢˜
    if 'C#' in str(skills['languages']):
        lines.append("### C#åŸºç¡€")
        lines.append("- [ ] å€¼ç±»å‹å’Œå¼•ç”¨ç±»å‹çš„åŒºåˆ«ï¼Ÿä»€ä¹ˆæ˜¯è£…ç®±æ‹†ç®±ï¼Ÿ")
        lines.append("- [ ] ä»€ä¹ˆæ˜¯GCï¼Ÿå¦‚ä½•é¿å…GC Allocï¼Ÿ")
        lines.append("- [ ] å§”æ‰˜å’Œäº‹ä»¶çš„åŒºåˆ«ï¼Ÿ")
        lines.append("")

    if 'Unity' in str(skills['engines']):
        lines.append("### Unityä¸“é¡¹")
        lines.append("- [ ] Unityç”Ÿå‘½å‘¨æœŸå‡½æ•°çš„æ‰§è¡Œé¡ºåºï¼Ÿ")
        lines.append("- [ ] MonoBehaviourçš„åŸç†ï¼Ÿ")
        lines.append("- [ ] Resources.Loadå’ŒAddressableçš„åŒºåˆ«ï¼Ÿ")
        lines.append("")

    if 'C++' in str(skills['languages']):
        lines.append("### C++åŸºç¡€")
        lines.append("- [ ] æŒ‡é’ˆå’Œå¼•ç”¨çš„åŒºåˆ«ï¼Ÿ")
        lines.append("- [ ] ä»€ä¹ˆæ˜¯å†…å­˜æ³„æ¼ï¼Ÿå¦‚ä½•é¿å…ï¼Ÿ")
        lines.append("- [ ] è™šå‡½æ•°çš„ä½œç”¨ï¼Ÿ")
        lines.append("")

    # è–„å¼±ç¯èŠ‚éªŒè¯
    lines.append("### è–„å¼±ç¯èŠ‚éªŒè¯")
    for risk in analysis['risks'][:3]:
        # ä»é£é™©ç‚¹ç”ŸæˆéªŒè¯é—®é¢˜
        if 'C++' in risk:
            lines.append("- [ ] C++ä¸­æ™ºèƒ½æŒ‡é’ˆæœ‰å“ªäº›ç±»å‹ï¼Ÿå„æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ")
        elif 'Unity' in risk and 'C#' in risk:
            lines.append("- [ ] è¯·å†™ä¸€ä¸ªç®€å•çš„Unityè„šæœ¬ç¤ºä¾‹")
        elif 'æ¶æ„' in risk or 'è®¾è®¡æ¨¡å¼' in risk:
            lines.append("- [ ] é¡¹ç›®ä¸­ä½¿ç”¨äº†å“ªäº›è®¾è®¡æ¨¡å¼ï¼Ÿå•ä¾‹æ¨¡å¼çš„ä¼˜ç¼ºç‚¹ï¼Ÿ")
        elif 'ç½‘ç»œ' in risk:
            lines.append("- [ ] TCPå’ŒUDPçš„åŒºåˆ«ï¼Ÿæ¸¸æˆä¸­å¦‚ä½•é€‰æ‹©ï¼Ÿ")
        else:
            lines.append(f"- [ ] è¯·è¯¦ç»†è¯´æ˜ï¼š{risk.replace('éœ€éªŒè¯', '').replace('éœ€ç¡®è®¤', '')}")
    lines.append("")

    # é€šç”¨é—®é¢˜
    lines.append("### é€šç”¨å¿…é—®é¢˜")
    lines.append("- [ ] è§£é‡ŠA*å¯»è·¯ç®—æ³•çš„åŸç†")
    lines.append("- [ ] å¦‚ä½•å®ç°ä¸€ä¸ªå¯¹è±¡æ± ï¼Ÿæœ‰ä»€ä¹ˆå¥½å¤„ï¼Ÿ")
    lines.append("")

    # é˜¶æ®µ4: éæŠ€æœ¯ç´ è´¨
    lines.append("## é˜¶æ®µ4: éæŠ€æœ¯ç´ è´¨ (2åˆ†é’Ÿ)")
    lines.append("- [ ] é¡¹ç›®ä¸ä»–äººåˆä½œæœ‰æ²¡æœ‰é‡åˆ°è¿‡çŸ›ç›¾ï¼Ÿå¦‚ä½•å¤„ç†ï¼Ÿ")
    lines.append("- [ ] åˆç†å®‰æ’éœ€æ±‚çš„æƒ…å†µä¸‹ï¼Œæ²¡åšå®Œçš„éœ€æ±‚ä¼šå¦‚ä½•å¤„ç†ï¼Ÿ")
    lines.append("- [ ] å·¥ä½œè¿‡ç¨‹ä¸­é‡åˆ°ä¸æ‡‚çš„é—®é¢˜ä¼šå¦‚ä½•è§£å†³ï¼Ÿ")
    lines.append("")

    # é˜¶æ®µ5: å€™é€‰äººæé—®
    lines.append("## é˜¶æ®µ5: å€™é€‰äººæé—® (3åˆ†é’Ÿ)")
    lines.append("- [ ] ç»™å€™é€‰äººæé—®æœºä¼š")
    lines.append("- **å€™é€‰äººé—®é¢˜**: ___")
    lines.append("")

    # è¯„åˆ†è®°å½•è¡¨
    lines.append("## è¯„åˆ†è®°å½•è¡¨")
    lines.append("")
    lines.append("| ç»´åº¦ | æƒé‡ | å¾—åˆ† | å¤‡æ³¨ |")
    lines.append("|------|------|------|------|")
    lines.append("| æŠ€æœ¯èƒ½åŠ› | 35% | ___ | Unity/C#/æ¶æ„ |")
    lines.append("| é¡¹ç›®ç»éªŒ | 25% | ___ | é¡¹ç›®æ·±åº¦/å¤æ‚åº¦ |")
    lines.append("| ç®—æ³•åŸºç¡€ | 15% | ___ | æ•°æ®ç»“æ„/ç®—æ³• |")
    lines.append("| å›¢é˜Ÿåä½œ | 10% | ___ | æ²Ÿé€š/åä½œæ„è¯† |")
    lines.append("| å‘å±•æ½œåŠ› | 10% | ___ | å­¦ä¹ èƒ½åŠ›/è§†é‡ |")
    lines.append("| æ–‡åŒ–åŒ¹é… | 5% | ___ | ä»·å€¼è§‚/æ€åº¦ |")
    lines.append("| **æ€»åˆ†** | **100%** | ___ | |")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append(f"*é¢è¯•é—®é¢˜æ¸…å•ç”±ç®€å†è‡ªåŠ¨åˆ†æç³»ç»Ÿç”Ÿæˆ*")
    lines.append(f"*ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

    content = "\n".join(lines)

    # ä¿å­˜æ–‡ä»¶
    filename = f"é¢è¯•é—®é¢˜æ¸…å•_{name}_{today}.md"
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        filepath = os.path.join(output_dir, filename)
    else:
        filepath = filename

    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)

    return filepath


def main():
    parser = argparse.ArgumentParser(
        description='ä»PDFç®€å†è‡ªåŠ¨ç”ŸæˆæŠ€èƒ½è¯„ä¼°æŠ¥å‘Šå’Œé¢è¯•é—®é¢˜æ¸…å•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•
  python3 analyze_resume.py /path/to/resume.pdf

  # æŒ‡å®šè¾“å‡ºç›®å½•
  python3 analyze_resume.py /path/to/resume.pdf -o ./reports

  # æŒ‡å®šå€™é€‰äººå§“å
  python3 analyze_resume.py /path/to/resume.pdf --name "å¼ ä¸‰"
        """
    )

    parser.add_argument('pdf_path', help='PDFç®€å†æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output-dir', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸ºPDFæ‰€åœ¨ç›®å½•ï¼‰')
    parser.add_argument('--name', help='å€™é€‰äººå§“åï¼ˆå¦‚PDFä¸­æ— æ³•è‡ªåŠ¨è¯†åˆ«ï¼‰')

    args = parser.parse_args()

    print("=" * 60)
    print("  ç®€å†è‡ªåŠ¨åˆ†æç³»ç»Ÿ")
    print("=" * 60)
    print()

    # æ­¥éª¤1: æå–PDFæ–‡æœ¬
    print("ğŸ“„ æ­£åœ¨æå–PDFæ–‡æœ¬...")
    try:
        text = extract_pdf_text(args.pdf_path)
        print(f"   âœ“ æˆåŠŸæå– {len(text)} å­—ç¬¦")
    except Exception as e:
        print(f"   âœ— é”™è¯¯: {e}")
        sys.exit(1)

    # æ­¥éª¤2: è§£æç®€å†ä¿¡æ¯
    print("\nğŸ” æ­£åœ¨è§£æç®€å†ä¿¡æ¯...")
    parsed_data = parse_resume(text)

    # å¦‚æœæŒ‡å®šäº†å§“åï¼Œè¦†ç›–è‡ªåŠ¨è¯†åˆ«çš„
    if args.name:
        parsed_data['name'] = args.name

    print(f"   âœ“ å§“å: {parsed_data['name']}")
    print(f"   âœ“ æœŸæœ›å²—ä½: {parsed_data['position']}")
    print(f"   âœ“ å·¥ä½œå¹´é™: {parsed_data['experience_years']}")
    print(f"   âœ“ ç¼–ç¨‹è¯­è¨€: {', '.join(parsed_data['skills']['languages']) or 'æœªè¯†åˆ«'}")
    print(f"   âœ“ æ¸¸æˆå¼•æ“: {', '.join(parsed_data['skills']['engines']) or 'æœªè¯†åˆ«'}")
    print(f"   âœ“ é¡¹ç›®æ•°é‡: {len(parsed_data['projects'])}")

    # æ­¥éª¤3: åˆ†ææŠ€èƒ½
    print("\nğŸ“Š æ­£åœ¨åˆ†ææŠ€èƒ½ç†Ÿç»ƒåº¦...")
    analysis = analyze_skills(parsed_data)
    print(f"   âœ“ è¯†åˆ«æŠ€èƒ½: {len(analysis['skill_levels'])} é¡¹")
    print(f"   âœ“ æ¨èç­‰çº§: {analysis['recommendation_level']}çº§")

    # å§‹ç»ˆä½¿ç”¨ PDF æ‰€åœ¨ç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•
    output_dir = os.path.dirname(os.path.abspath(args.pdf_path))

    # æ­¥éª¤4: ç”ŸæˆæŠ€èƒ½è¯„ä¼°æŠ¥å‘Š
    print("\nğŸ“ æ­£åœ¨ç”ŸæˆæŠ€èƒ½è¯„ä¼°æŠ¥å‘Š...")
    report_path = generate_skill_report(parsed_data, analysis, output_dir)
    print(f"   âœ“ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # æ­¥éª¤5: ç”Ÿæˆé¢è¯•é—®é¢˜æ¸…å•
    print("\nğŸ“‹ æ­£åœ¨ç”Ÿæˆé¢è¯•é—®é¢˜æ¸…å•...")
    question_path = generate_question_list(parsed_data, analysis, output_dir)
    print(f"   âœ“ æ¸…å•å·²ä¿å­˜: {question_path}")

    # å®Œæˆ
    print("\n" + "=" * 60)
    print("  åˆ†æå®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"   1. {report_path}")
    print(f"   2. {question_path}")
    print()


if __name__ == "__main__":
    main()
